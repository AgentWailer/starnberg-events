# Auto-Update System fÃ¼r Events

Dieses System automatisiert die Aktualisierung der Events auf der Starnberg-Events-Website.

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions (tÃ¤glich 6:00 Uhr)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Scraper lÃ¤uft (scripts/scrape-events.mjs)  â”‚
â”‚  2. Events von allen Quellen fetchen           â”‚
â”‚  3. Merge + Deduplizierung                     â”‚
â”‚  4. Speichern in events.json                   â”‚
â”‚  5. Commit + Push (wenn Ã„nderungen)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cloudflare Pages rebuildet automatisch        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Lokaler Test

```bash
# Dependencies installieren
npm install

# Scraper lokal ausfÃ¼hren
npm run scrape

# Ergebnis prÃ¼fen
git diff src/data/events.json
```

## ğŸ”§ Funktionen

### âœ… Implementiert

- **GrundgerÃ¼st**: Event-Scraping-System mit Deduplizierung
- **Merge-Logik**: 
  - BehÃ¤lt manuell hinzugefÃ¼gte Events (mit `"manual": true`)
  - Entfernt vergangene Events automatisch
  - Dedupliziert basierend auf Titel + Datum
  - Sortiert Events chronologisch
- **Auto-Kategorisierung**: Versucht automatisch Kategorie zu erkennen
- **Auto-Tagging**: Weist Tags basierend auf Keywords zu
- **GitHub Actions**: Workflow lÃ¤uft tÃ¤glich + manuell auslÃ¶sbar

### âš ï¸ TODO: Scraper implementieren

Alle Scraper sind aktuell **Stubs**. Jeder muss individuell implementiert werden:

| Quelle | PrioritÃ¤t | Schwierigkeit | Status |
|--------|-----------|---------------|--------|
| **beccult** | ğŸ”´ Hoch | â­ Mittel | âŒ TODO |
| **starnbergammersee** | ğŸ”´ Hoch | â­â­ Mittel-Hoch | âŒ TODO |
| **PFC PÃ¶cking** | ğŸ”´ Hoch | â­ Einfach | âŒ TODO |
| **Olympiapark** | ğŸŸ¡ Mittel | â­â­ Mittel-Hoch | âŒ TODO |
| **Deutsches Museum** | ğŸŸ¡ Mittel | â­â­ Mittel | âŒ TODO |
| **Hellabrunn** | ğŸŸ¡ Mittel | â­â­ Mittel | âŒ TODO |
| **Tegernsee** | ğŸŸ¢ Niedrig | â­â­ Mittel | âŒ TODO |
| **Garmisch** | ğŸŸ¢ Niedrig | â­â­ Mittel | âŒ TODO |
| **muenchen.de** | ğŸŸ¢ Niedrig | â­â­â­ Schwer | âŒ TODO (sehr komplex, evtl. API?) |

## ğŸ› ï¸ Scraper implementieren

### Beispiel-Template:

```javascript
import * as cheerio from 'cheerio';

async function scrapeExampleSource() {
  const response = await fetch('https://example.com/events');
  const html = await response.text();
  const $ = cheerio.load(html);
  
  const events = [];
  
  // Selektoren anpassen!
  $('.event-item').each((i, elem) => {
    const title = $(elem).find('.title').text().trim();
    const dateStr = $(elem).find('.date').text().trim();
    const time = $(elem).find('.time').text().trim();
    const location = $(elem).find('.location').text().trim();
    const url = $(elem).find('a').attr('href');
    
    // Datum parsen (Format anpassen!)
    const date = parseDate(dateStr); // Eigene Funktion
    
    // Event erstellen
    events.push({
      title,
      date,
      time,
      location,
      address: '',
      description: '',
      category: detectCategory(title, ''),
      tags: detectTags(title, ''),
      url,
      source: 'example-source',
      region: 'starnberg-ammersee',
      venue: null,
      isHighlight: false
    });
  });
  
  return events;
}
```

### Wichtige Regeln:

1. **Datum-Format**: `YYYY-MM-DD` (ISO 8601)
2. **Zeit-Format**: `HH:MM` (24h)
3. **Deduplizierung**: Scraper mÃ¼ssen keine Duplikate prÃ¼fen (macht die Merge-Funktion)
4. **Fehlerbehandlung**: Scraper sollten bei Fehlern leere Arrays zurÃ¼ckgeben, nicht crashen
5. **Highlights**: Nur echte Highlights markieren (groÃŸe Events, bekannte Acts)
6. **Kategorie**: `kinder`, `familie`, oder `erwachsene`
7. **Tags**: Aus der Liste: `musik`, `theater`, `kunst`, `sport`, `natur`, `markt`, `bildung`, `fest`, `show`, `indoor`

### Spezielle Anforderungen:

- **Gasteig/MÃ¼nchen.de**: NUR Top-Events (sonst 2000+ Events) â†’ Highlights filtern
- **Tegernsee/Garmisch**: Fokus auf Highlights (Festivals, groÃŸe Events)

## ğŸ“Š Output

Der Scraper schreibt nach `src/data/events.json`:

```json
{
  "lastUpdated": "2026-02-04",
  "sources": ["beccult", "starnbergammersee", ...],
  "regions": { ... },
  "eventCount": 91,
  "events": [ ... ]
}
```

## ğŸ”„ GitHub Actions

**Workflow**: `.github/workflows/update-events.yml`

- **Trigger**: TÃ¤glich um 6:00 Uhr morgens (Europe/Berlin)
- **Manuell**: Via GitHub UI â†’ Actions â†’ "Auto-Update Events" â†’ "Run workflow"
- **Commit**: Nur wenn sich `events.json` Ã¤ndert
- **Commit Message**: `chore: auto-update events [skip ci]`
- **Auto-Deploy**: Cloudflare Pages rebuildet bei jedem Push auf `main`

## ğŸš¨ Wichtig

- **NICHT committen/pushen** wÃ¤hrend lokaler Tests!
- **Backup**: Vor grÃ¶ÃŸeren Ã„nderungen `events.json` sichern
- **Testing**: Immer erst `npm run scrape` lokal testen
- **Scraper-QualitÃ¤t**: Lieber 10 korrekte Events als 100 fehlerhafte

## ğŸ¯ NÃ¤chste Schritte

1. **Beccult-Scraper** implementieren (lokale Quelle, wichtig!)
2. **StarnbergAmmersee-Scraper** implementieren (Hauptquelle)
3. **PFC-Scraper** implementieren (lokale Quelle)
4. Testen und weitere Quellen hinzufÃ¼gen

## ğŸ“ Logs & Debugging

```bash
# Scraper-Output zeigt:
# - Welche Quellen gescraped wurden
# - Wie viele Events gefunden wurden
# - Anzahl hinzugefÃ¼gter/entfernter Events

npm run scrape

# GitHub Actions Logs:
# GitHub â†’ Actions â†’ Workflow â†’ Run Details
```
